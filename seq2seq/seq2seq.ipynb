{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "<img src=\"../imgs/EII-ULPGC-logo.jpeg\" width=\"430px\" align=\"right\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **NOTEBOOK 14**\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# **Modelos del lenguaje basados en redes neuronales artificiales**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Modelos seq2seq 1**\n",
    "\n",
    "La arquitectura seq2seq, o secuencia a secuencia, es un tipo de modelo de red neuronal utilizado en el aprendizaje profundo para convertir secuencias de entrada en secuencias de salida. Es especialmente popular para tareas como traducción automática, generación de texto, y reconocimiento de voz. Se forma mediante la unión de dos componentes principales: un **codificador** y un **decodificador**.\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"imgs/seq2seq_.svg\" width=\"80%\">\n",
    "</p>\n",
    "\n",
    "\n",
    "#### **Codificador (Encoder)**\n",
    "\n",
    "El codificador toma la secuencia de entrada y la procesa para generar una representación interna, a menudo en forma de un vector de contexto o una serie de estados ocultos. Aquí está el proceso detallado:\n",
    "\n",
    "1. **Entrada de la secuencia**: El modelo toma una secuencia de entrada (por ejemplo, una frase en inglés si estamos haciendo traducción inglés-español).\n",
    "\n",
    "2. **Embedding de palabras**: Cada palabra o token de la secuencia se transforma en un vector mediante una capa de embebido (embedding).\n",
    "\n",
    "3. **Procesamiento recurrente**: Los vectores embebidos se pasan a través de capas recurrentes (como LSTM o GRU) para procesar la secuencia. En cada paso temporal, la red actualiza su estado oculto basándose en el token actual y el estado oculto anterior.\n",
    "\n",
    "4. **Captura de contexto**: El último estado oculto de la red (o una combinación de todos los estados ocultos, dependiendo del diseño) se toma como la representación condensada de la secuencia completa. Este vector de contexto captura la información esencial de la entrada.\n",
    "\n",
    "### **Decodificador (Decoder)**\n",
    "\n",
    "El decodificador utiliza la representación generada por el codificador para producir la secuencia de salida.\n",
    "\n",
    "1. **Inicialización**: El decodificador se inicializa con el estado oculto final del codificador. En algunos diseños, el vector de contexto también se usa directamente como parte de la entrada en cada paso del decodificador.\n",
    "\n",
    "2. **Generación de la secuencia de salida**: En cada paso, el decodificador genera un token de la secuencia de salida.\n",
    "\n",
    "   - **Estado oculto**: Se actualiza en cada paso basándose en la entrada actual y el estado oculto anterior.\n",
    "   - **Entrada**: Puede ser el token de salida del paso anterior o un token especial para indicar el inicio de la secuencia.\n",
    "   - **Salida**: Un vector que se transforma en las probabilidades de los diferentes tokens posibles para el siguiente paso de la secuencia. Esto se hace típicamente con una capa softmax.\n",
    "\n",
    "3. **Terminación**: El proceso continúa hasta que se genera un token de final de secuencia o se alcanza una longitud máxima de secuencia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Implementación**\n",
    "\n",
    "Vamos a implementar un sencillo modelo seq2seq que realice la suma de dos números decimales de, como máximo, 3 cifras. La entrada será una cadena de texto con el formato \"123+456\" y la salida será una cadena de texto con el formato \"0579\".\n",
    "\n",
    "#### **Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import string\n",
    "import torch\n",
    "\n",
    "allowed_chars = string.digits + '+'\n",
    "\n",
    "class Generator():\n",
    "    def __init__(self) -> None:\n",
    "        pass\n",
    "\n",
    "    # Método para crear un ejemplo de entrenamiento\n",
    "    def sample(self):\n",
    "        s1 = random.randint(0, 999)\n",
    "        s2 = random.randint(0, 999)\n",
    "        r = s1 + s2\n",
    "        s1_string = str(s1).zfill(3)\n",
    "        s2_string = str(s2).zfill(3)\n",
    "        output = str(r).zfill(4)\n",
    "        input = s1_string + \"+\" + s2_string\n",
    "        return input, output\n",
    "    \n",
    "    # Método para crear un lote de ejemplos de entrenamiento\n",
    "    def batch(self, n):\n",
    "        inputs = []\n",
    "        outputs = []\n",
    "        for _ in range(n):\n",
    "            input, output = self.sample()\n",
    "            inputs.append(input)\n",
    "            outputs.append(output)\n",
    "        return inputs, outputs\n",
    "    \n",
    "    # Método para codificar una cadena de caracteres en un tensor one-hot\n",
    "    def string_to_tensor(self, s):\n",
    "        tensor = torch.zeros(len(s), len(allowed_chars))\n",
    "        for i, char in enumerate(s):\n",
    "            tensor[i, allowed_chars.index(char)] = 1\n",
    "        return tensor\n",
    "\n",
    "    # Método para decodificar un tensor one-hot en una cadena de caracteres\n",
    "    def tensor_to_string(self, tensor):\n",
    "        _, max_idx = tensor.max(1)\n",
    "        return ''.join([allowed_chars[i] for i in max_idx])\n",
    "    \n",
    "    # Método para generar un lote de ejemplos de entrenamiento codificados\n",
    "    def batch_to_tensor(self, n):\n",
    "        seq_in = []\n",
    "        seq_out = []\n",
    "        inputs, outputs = self.batch(n)\n",
    "        # print(inputs, outputs)\n",
    "        for input, output in zip(inputs, outputs):\n",
    "            seq_in.append(self.string_to_tensor(input))\n",
    "            seq_out.append(self.string_to_tensor(output))\n",
    "        return torch.stack(seq_in), torch.stack(seq_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Modelo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "\n",
    "# Definir la arquitectura del modelo seq2seq\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.encoder = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
    "        self.decoder = nn.LSTM(hidden_size, hidden_size, batch_first=True)\n",
    "        self.output = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, input, hidden=None):\n",
    "        dummy_input = input + torch.empty(self.encoder.input_size)\n",
    "        dummy_input = pad_sequence(dummy_input, batch_first=True, padding_value=0)\n",
    "        input = dummy_input[:]\n",
    "        _, (hn_enc, cn_enc) = self.encoder(input, hidden)\n",
    "        latent_tensor = hn_enc[0].unsqueeze(1).repeat(1, 4, 1)\n",
    "        out_dec, (_, _) = self.decoder(latent_tensor, (hn_enc, cn_enc))\n",
    "        out = F.softmax(self.output(out_dec), dim=2)\n",
    "        return out\n",
    "    \n",
    "model = Seq2Seq(input_size=len(allowed_chars), hidden_size=128, output_size=len(allowed_chars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Entrenamiento**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87a3f7c75c474620964d6b6406840bb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 30\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Entrenar el modelo\u001b[39;00m\n\u001b[1;32m     29\u001b[0m dg \u001b[38;5;241m=\u001b[39m Generator()\n\u001b[0;32m---> 30\u001b[0m train(model, optimizer, loss_fn, dg, \u001b[38;5;241m5000\u001b[39m, \u001b[38;5;241m128\u001b[39m)\n\u001b[1;32m     33\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(history, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[7], line 14\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, loss_fn, dg, n_epochs, batch_size)\u001b[0m\n\u001b[1;32m     12\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     13\u001b[0m x, y \u001b[38;5;241m=\u001b[39m dg\u001b[38;5;241m.\u001b[39mbatch_to_tensor(batch_size)\n\u001b[0;32m---> 14\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model(x)\n\u001b[1;32m     15\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(y_pred, y)\n\u001b[1;32m     16\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[4], line 21\u001b[0m, in \u001b[0;36mSeq2Seq.forward\u001b[0;34m(self, input, hidden)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m dummy_input[:]\n\u001b[1;32m     20\u001b[0m _, (hn_enc, cn_enc) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(\u001b[38;5;28minput\u001b[39m, hidden)\n\u001b[0;32m---> 21\u001b[0m latent_tensor \u001b[38;5;241m=\u001b[39m hn_enc[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mrepeat(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     22\u001b[0m out_dec, (_, _) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder(latent_tensor, (hn_enc, cn_enc))\n\u001b[1;32m     23\u001b[0m out \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39msoftmax(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(out_dec), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "Cell \u001b[0;32mIn[4], line 21\u001b[0m, in \u001b[0;36mSeq2Seq.forward\u001b[0;34m(self, input, hidden)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m dummy_input[:]\n\u001b[1;32m     20\u001b[0m _, (hn_enc, cn_enc) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(\u001b[38;5;28minput\u001b[39m, hidden)\n\u001b[0;32m---> 21\u001b[0m latent_tensor \u001b[38;5;241m=\u001b[39m hn_enc[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mrepeat(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     22\u001b[0m out_dec, (_, _) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder(latent_tensor, (hn_enc, cn_enc))\n\u001b[1;32m     23\u001b[0m out \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39msoftmax(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(out_dec), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1457\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.SafeCallWrapper.__call__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:701\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1395\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1344\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:312\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.do_wait_suspend\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/debugpy/_vendored/pydevd/pydevd.py:2070\u001b[0m, in \u001b[0;36mPyDB.do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n\u001b[1;32m   2067\u001b[0m             from_this_thread\u001b[38;5;241m.\u001b[39mappend(frame_custom_thread_id)\n\u001b[1;32m   2069\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_threads_suspended_single_notification\u001b[38;5;241m.\u001b[39mnotify_thread_suspended(thread_id, thread, stop_reason):\n\u001b[0;32m-> 2070\u001b[0m         keep_suspended \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_wait_suspend(thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\n\u001b[1;32m   2072\u001b[0m frames_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2074\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keep_suspended:\n\u001b[1;32m   2075\u001b[0m     \u001b[38;5;66;03m# This means that we should pause again after a set next statement.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/debugpy/_vendored/pydevd/pydevd.py:2106\u001b[0m, in \u001b[0;36mPyDB._do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\u001b[0m\n\u001b[1;32m   2103\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_input_hook()\n\u001b[1;32m   2105\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_internal_commands()\n\u001b[0;32m-> 2106\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.01\u001b[39m)\n\u001b[1;32m   2108\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcancel_async_evaluation(get_current_thread_id(thread), \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mid\u001b[39m(frame)))\n\u001b[1;32m   2110\u001b[0m \u001b[38;5;66;03m# process any stepping instructions\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import trange\n",
    "\n",
    "history = []\n",
    "\n",
    "# Bucle de entrenamiento\n",
    "def train(model, optimizer, loss_fn, dg, n_epochs, batch_size):\n",
    "    pbar = trange(n_epochs)\n",
    "    for epoch in pbar:\n",
    "        total_loss = 0\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        x, y = dg.batch_to_tensor(batch_size)\n",
    "        y_pred = model(x)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        # Print the loss every 10 epochs\n",
    "        if epoch % 100 == 0:\n",
    "            pbar.set_postfix_str(f\"{total_loss:.4} loss\")\n",
    "            history.append(total_loss)\n",
    "\n",
    "# Definir la función de pérdida y el optimizador\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Entrenar el modelo\n",
    "dg = Generator()\n",
    "train(model, optimizer, loss_fn, dg, 5000, 128)\n",
    "\n",
    "\n",
    "plt.plot(history, label='loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Evaluación**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "829+827 = 0000 (expected 1656) ERROR\n",
      "118+644 = 0000 (expected 0762) ERROR\n",
      "659+695 = 0000 (expected 1354) ERROR\n",
      "202+114 = 0000 (expected 0316) ERROR\n",
      "571+566 = 0000 (expected 1137) ERROR\n",
      "299+135 = 0000 (expected 0434) ERROR\n",
      "248+570 = 0000 (expected 0818) ERROR\n",
      "932+132 = 0000 (expected 1064) ERROR\n",
      "510+382 = 0000 (expected 0892) ERROR\n",
      "398+257 = 0000 (expected 0655) ERROR\n",
      "--------------------\n",
      "result: 0/10\n"
     ]
    }
   ],
   "source": [
    "# Evaluar el modelo\n",
    "def evaluate(model, n):\n",
    "    x, y = dg.batch_to_tensor(n)\n",
    "    y_pred = model(x)\n",
    "    correct = 0\n",
    "    for i in range(n):\n",
    "        query = dg.tensor_to_string(x[i])\n",
    "        pred = dg.tensor_to_string(y_pred[i])\n",
    "        result = dg.tensor_to_string(y[i])\n",
    "        print(f\"{query} = {pred} (expected {result}) {'OK' if pred == result else 'ERROR'}\")\n",
    "        if pred == result:\n",
    "            correct += 1\n",
    "    print(\"-\"*20)\n",
    "    print(f\"result: {correct}/{n}\")\n",
    "\n",
    "evaluate(model, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es importante destacar que el modelo no realiza una suma de números siguiendo un procedimiento aritmético, sino que aprende a generar la secuencia de salida correcta mediante un proceso de traducción aprendido a partir de los datos de entrenamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Ejercicio 1\n",
    "\n",
    "Modifica el código anterior para que el modelo pueda recibir secuencias de longitud variable. Para ello, usa el generador de datos siguiente. Otra de las cosas que debes tener en cuenta es que el generador devuelve una lista de tensores, esto es así para que puedas usar la función `pad_sequence` para rellenar las secuencias más cortas con ceros. Consulta la referencia de la función para ver cómo se usa. El parámetro `batch_first` es importante para que la función sepa si los datos están en formato `(batch_size, seq_len, input_size)` o `(seq_len, batch_size, input_size)`. Nos interesa que estén en el primer formato.\n",
    "\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import string\n",
    "import torch\n",
    "\n",
    "allowed_chars = string.digits + '+' + '#'  # <-- Añadimos el caracter # como padding para la salida\n",
    "\n",
    "class Generator2():\n",
    "    def __init__(self) -> None:\n",
    "        pass\n",
    "\n",
    "    # Método para crear un ejemplo de entrenamiento\n",
    "    def sample(self):\n",
    "        s1 = random.randint(0, 9999)\n",
    "        s2 = random.randint(0, 9999)\n",
    "        r = s1 + s2\n",
    "        s1_string = str(s1)\n",
    "        s2_string = str(s2)\n",
    "        output = str(r)\n",
    "        input = s1_string + \"+\" + s2_string\n",
    "        return input, output\n",
    "    \n",
    "    # Método para crear un lote de ejemplos de entrenamiento\n",
    "    def batch(self, n):\n",
    "        inputs = []\n",
    "        outputs = []\n",
    "        for _ in range(n):\n",
    "            input, output = self.sample()\n",
    "            inputs.append(input)\n",
    "            outputs.append(output)\n",
    "        return inputs, outputs\n",
    "    \n",
    "    # Método para codificar una cadena de caracteres en un tensor one-hot\n",
    "    def string_to_tensor(self, s):\n",
    "        tensor = torch.zeros(len(s), len(allowed_chars))\n",
    "        for i, char in enumerate(s):\n",
    "            tensor[i, allowed_chars.index(char)] = 1\n",
    "        return tensor\n",
    "\n",
    "    # Método para decodificar un tensor one-hot en una cadena de caracteres\n",
    "    def tensor_to_string(self, tensor):\n",
    "        _, max_idx = tensor.max(1)\n",
    "        return ''.join([allowed_chars[i] for i in max_idx])\n",
    "    \n",
    "    # Método para generar un lote de ejemplos de entrenamiento codificados\n",
    "    def batch_to_tensor(self, n):\n",
    "        seq_in = []\n",
    "        seq_out = []\n",
    "        inputs, outputs = self.batch(n)\n",
    "        for input, output in zip(inputs, outputs):\n",
    "            seq_in.append(self.string_to_tensor(input))\n",
    "            seq_out.append(self.string_to_tensor(output))\n",
    "        return seq_in, seq_out # <-- Devolvemos dos listas de tensores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]])]\n",
      "--------------------------------------------------\n",
      "[tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]]), tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]])]\n"
     ]
    }
   ],
   "source": [
    "gen = Generator2()\n",
    "batch_in, batch_out = gen.batch_to_tensor(2)\n",
    "print(batch_in)\n",
    "print(\"-\"*50)\n",
    "print(batch_out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
