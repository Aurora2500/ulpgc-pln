{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = fetch_20newsgroups()\n",
    "# dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividimos el DataFrame en datos y etiquetas\n",
    "X = dataframe['data']\n",
    "y = dataframe['target']\n",
    "\n",
    "# Dividimos los datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier, SGDClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(stop_words='english', max_features=10000)\n",
    "\n",
    "classifiers = [\n",
    "    ('naive_bayes', MultinomialNB()),\n",
    "    ('logistic_regression', LogisticRegression()),\n",
    "    ('support_vector_classifier', SVC()),\n",
    "    ('tree', DecisionTreeClassifier()),\n",
    "    ('neighbors', KNeighborsClassifier()),\n",
    "    ('ridge_classifier', RidgeClassifier()),\n",
    "    ('SGD_classifier', SGDClassifier())\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelines = [\n",
    "    Pipeline([\n",
    "        ('vect', vectorizer),\n",
    "        ('clf', clf[1])\n",
    "    ])\n",
    "    for clf\n",
    "    in classifiers\n",
    "]\n",
    "\n",
    "for pl in pipelines:\n",
    "    pl.fit(X_train, y_train)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ridge_classifier': 0.7242841993637328, 'SGD_classifier': 0.8275008837044893}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = [\n",
    "    pl.predict(X_test)\n",
    "    for pl\n",
    "    in pipelines\n",
    "]\n",
    "\n",
    "accuracy = {\n",
    "    cl[0]: accuracy_score(y_test, p)\n",
    "    for cl, p\n",
    "    in zip(classifiers, predictions)\n",
    "}\n",
    "\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>0.874160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>naive_bayes</td>\n",
       "      <td>0.840580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tree</td>\n",
       "      <td>0.653588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neighbors</td>\n",
       "      <td>0.479675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>support_vector_classifier</td>\n",
       "      <td>0.086603</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      method  accuracy\n",
       "1        logistic_regression  0.874160\n",
       "0                naive_bayes  0.840580\n",
       "3                       tree  0.653588\n",
       "4                  neighbors  0.479675\n",
       "2  support_vector_classifier  0.086603"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(((a[0], a[1]) for a in accuracy.items()), columns=[\"method\", \"accuracy\"]).sort_values(\"accuracy\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [\n",
    "    ('ridge_classifier', RidgeClassifier()),\n",
    "    ('SGD_classifier', SGDClassifier())\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SGD_classifier</td>\n",
       "      <td>0.827501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ridge_classifier</td>\n",
       "      <td>0.724284</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             method  accuracy\n",
       "1    SGD_classifier  0.827501\n",
       "0  ridge_classifier  0.724284"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(((a[0], a[1]) for a in accuracy.items()), columns=[\"method\", \"accuracy\"]).sort_values(\"accuracy\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import HalvingRandomSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Radka\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\model_selection\\_search.py:320: UserWarning: The total space of parameters 27 is smaller than n_iter=42. Running 27 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'penalty': 'l2', 'loss': 'perceptron'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_params = {\n",
    "    'loss': ['hinge', 'log_loss', 'modified_huber', 'squared_hinge', 'perceptron', 'squared_error', 'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive'],\n",
    "    'penalty': ['l1', 'l2', 'elasticnet'],\n",
    "}\n",
    "\n",
    "vectorizer.fit(X_train)\n",
    "Xvec_train = vectorizer.transform(X_train)\n",
    "\n",
    "clf = SGDClassifier()\n",
    "\n",
    "search = HalvingRandomSearchCV(clf, test_params, random_state=42)\n",
    "search.fit(Xvec_train, y_train)\n",
    "search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8342170378225522\n"
     ]
    }
   ],
   "source": [
    "best_clf = SGDClassifier(**search.best_params_)\n",
    "best_clf.fit(Xvec_train, y_train)\n",
    "\n",
    "Xvec_test = vectorizer.transform(X_test)\n",
    "\n",
    "prediction = best_clf.predict(Xvec_test)\n",
    "\n",
    "print(f\"Accuracy: {accuracy_score(prediction, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Radka\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Radka\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Radka\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Radka\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Radka\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Radka\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Radka\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Radka\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Radka\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Radka\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Radka\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Radka\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Radka\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Radka\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Radka\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Radka\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Radka\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Radka\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Radka\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Radka\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'penalty': 'l2', 'solver': 'lbfgs'}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "test_params = {\n",
    "    'solver': ['newton-cg', 'sag', 'saga', 'lbfgs'],\n",
    "    'penalty': ['l2', None],\n",
    "}\n",
    "\n",
    "vectorizer.fit(X_train)\n",
    "Xvec_train = vectorizer.transform(X_train)\n",
    "\n",
    "clf = LogisticRegression()\n",
    "\n",
    "search = GridSearchCV(clf, test_params)\n",
    "search.fit(Xvec_train, y_train)\n",
    "search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8405797101449275\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.94      0.92       117\n",
      "           1       0.62      0.83      0.71       138\n",
      "           2       1.00      0.03      0.05       142\n",
      "           3       0.53      0.81      0.64       145\n",
      "           4       0.77      0.85      0.81       157\n",
      "           5       0.78      0.85      0.82       136\n",
      "           6       0.72      0.82      0.77       137\n",
      "           7       0.88      0.90      0.89       164\n",
      "           8       0.89      0.94      0.91       155\n",
      "           9       0.91      0.96      0.93       141\n",
      "          10       0.98      0.93      0.95       136\n",
      "          11       1.00      0.88      0.94       156\n",
      "          12       0.86      0.83      0.84       144\n",
      "          13       0.93      0.93      0.93       145\n",
      "          14       0.95      0.91      0.93       152\n",
      "          15       0.93      0.91      0.92       150\n",
      "          16       0.93      0.94      0.93       150\n",
      "          17       0.97      0.93      0.95       135\n",
      "          18       0.85      0.88      0.87       137\n",
      "          19       0.83      0.68      0.75        92\n",
      "\n",
      "    accuracy                           0.84      2829\n",
      "   macro avg       0.86      0.84      0.82      2829\n",
      "weighted avg       0.86      0.84      0.83      2829\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Creamos un vectorizador y un clasificador Naive Bayes\n",
    "vectorizer = CountVectorizer(stop_words='english', max_features=10000)\n",
    "clf = MultinomialNB()\n",
    "\n",
    "# Creamos un pipeline que incluya el vectorizador y el clasificador\n",
    "pipeline = Pipeline([\n",
    "    ('vect', vectorizer),\n",
    "    ('clf', clf)\n",
    "])\n",
    "\n",
    "# Entrenamos el modelo\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Comprobar los resultados con los datos de prueba\n",
    "predictions = pipeline.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, predictions))\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8741604807352421\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93       117\n",
      "           1       0.71      0.77      0.74       138\n",
      "           2       0.78      0.82      0.80       142\n",
      "           3       0.74      0.77      0.76       145\n",
      "           4       0.87      0.78      0.83       157\n",
      "           5       0.81      0.82      0.81       136\n",
      "           6       0.83      0.83      0.83       137\n",
      "           7       0.87      0.90      0.88       164\n",
      "           8       0.90      0.92      0.91       155\n",
      "           9       0.87      0.94      0.90       141\n",
      "          10       0.94      0.92      0.93       136\n",
      "          11       0.99      0.93      0.96       156\n",
      "          12       0.79      0.79      0.79       144\n",
      "          13       0.91      0.94      0.93       145\n",
      "          14       0.99      0.91      0.95       152\n",
      "          15       0.90      0.93      0.92       150\n",
      "          16       0.92      0.95      0.93       150\n",
      "          17       0.97      0.99      0.98       135\n",
      "          18       0.93      0.82      0.88       137\n",
      "          19       0.87      0.75      0.81        92\n",
      "\n",
      "    accuracy                           0.87      2829\n",
      "   macro avg       0.88      0.87      0.87      2829\n",
      "weighted avg       0.88      0.87      0.87      2829\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Creamos un vectorizador y un clasificador Naive Bayes\n",
    "vectorizer = CountVectorizer(stop_words='english', max_features=10000)\n",
    "clf = LogisticRegression()\n",
    "\n",
    "# Creamos un pipeline que incluya el vectorizador y el clasificador\n",
    "pipeline = Pipeline([\n",
    "    ('vect', vectorizer),\n",
    "    ('clf', clf)\n",
    "])\n",
    "\n",
    "# Entrenamos el modelo\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Comprobar los resultados con los datos de prueba\n",
    "predictions = pipeline.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, predictions))\n",
    "print(classification_report(y_test, predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
